{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6789f489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 13:03:32.834629: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-12 13:03:33.015347: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-12 13:03:33.055328: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-12 13:03:33.763612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib64\n",
      "2023-01-12 13:03:33.763685: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib64\n",
      "2023-01-12 13:03:33.763693: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, LSTMCell, Conv2D, MaxPool2D, BatchNormalization, Flatten, Dense, Dropout\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc20f4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_his(img):\n",
    "    yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    y, u, v = cv2.split(yuv)\n",
    "    y = cv2.equalizeHist(y)\n",
    "    yuv = cv2.merge([y, u, v])\n",
    "    his_img = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)\n",
    "    return his_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ed4be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_csv = pd.read_csv('label.csv')\n",
    "train_data = []\n",
    "\n",
    "for x in range(10):\n",
    "    img = cv2.imread(f'./Segments/{info_csv[\"filename\"][x]}.png')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    rect_mask = np.zeros(img.shape[:2], dtype=\"uint8\")           #black mask with shape of spectrogram \n",
    "    cv2.rectangle(rect_mask,(79,57),(576,427),255,-1)              #fill area we want to keep with white\n",
    "\n",
    "    masked_img = cv2.bitwise_and(img, img, mask=rect_mask)   #apply\n",
    "\n",
    "\n",
    "    output_img = masked_img[57:427,79:576]                    #resize image to fit in model\n",
    "    output_img = cv2.resize(output_img, (448, 448))\n",
    "    output_img = pre_his(output_img)\n",
    "\n",
    "    output_img = cv2.normalize(output_img, None, 0, 1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    train_data.append(output_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b23064fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Timestep(img_height, img_width, color_channels, num_classes, states):\n",
    "    \n",
    "    input_batch = Input(shape=(img_height, img_width, color_channels))\n",
    "    \n",
    "    cnn_network = Conv2D(4, (3,3), padding='same', activation='relu')(input_batch)\n",
    "    cnn_network = Conv2D(4, (3,3), padding='same', activation='relu')(cnn_network)\n",
    "    cnn_network = BatchNormalization()(cnn_network)\n",
    "    cnn_network = MaxPool2D(pool_size=(2,2), padding='same', strides=(4,4))(cnn_network)\n",
    "    \n",
    "    cnn_network = Conv2D(8, (3,3), padding='same', activation='relu')(cnn_network)\n",
    "    cnn_network = Conv2D(8, (3,3), padding='same', activation='relu')(cnn_network)\n",
    "    cnn_network = BatchNormalization()(cnn_network)\n",
    "    cnn_network = MaxPool2D(pool_size=(2,2), padding='same', strides=(4,4))(cnn_network)\n",
    "    \n",
    "    cnn_network = Conv2D(8, (3,3), padding='same', activation='relu')(cnn_network)\n",
    "    cnn_network = Conv2D(8, (3,3), padding='same', activation='relu')(cnn_network)\n",
    "    cnn_network = BatchNormalization()(cnn_network)\n",
    "    cnn_network = MaxPool2D(pool_size=(2,2), padding='same', strides=(4,4))(cnn_network)\n",
    "    \n",
    "    cnn_network = Conv2D(16, (3,3), padding='same', activation='relu')(cnn_network)\n",
    "    cnn_network = Conv2D(16, (3,3), padding='same', activation='relu')(cnn_network)\n",
    "    cnn_network = BatchNormalization()(cnn_network)\n",
    "    cnn_network = MaxPool2D(pool_size=(2,2), padding='same', strides=(4,4))(cnn_network)\n",
    "    \n",
    "    cnn_network = Flatten()(cnn_network)\n",
    "    \n",
    "    lstm_network = LSTM(12, dropout=0.04, recurrent_dropout=0.04, return_state=True)(tf.expand_dims(cnn_network, axis=0))\n",
    "    dense_network = Dense(4,activation='relu')(lstm_network[0])\n",
    "    dense_network = Dropout(0.2)(dense_network)\n",
    "    dense_network = Dense(num_classes, activation='softmax')(dense_network)\n",
    "    \n",
    "    \n",
    "    full_network = Model(input_batch, dense_network)\n",
    "    return full_network, lstm_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92bfb683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 448, 448, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 448, 448, 4)       112       \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 448, 448, 4)       148       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 448, 448, 4)      16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 112, 112, 4)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 112, 112, 8)       296       \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 112, 112, 8)       584       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 112, 112, 8)      32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 28, 28, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 28, 28, 8)         584       \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 28, 28, 8)         584       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 28, 28, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 7, 7, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 7, 7, 16)          1168      \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 7, 7, 16)          2320      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 7, 7, 16)         64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 2, 2, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " tf.expand_dims_1 (TFOpLambd  (1, None, 64)            0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               [(1, 12),                 3696      \n",
      "                              (1, 12),                           \n",
      "                              (1, 12)]                           \n",
      "                                                                 \n",
      " dense_2 (Dense)             (1, 2)                    26        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (1, 2)                    0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (1, 2)                    6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,668\n",
      "Trainable params: 9,596\n",
      "Non-trainable params: 72\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "timestep, lstm_state = Timestep(448, 448, 3, 2, 0)\n",
    "timestep.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "798b1ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.5 0.5]], shape=(1, 2), dtype=float32)\n",
      "[<KerasTensor: shape=(1, 12) dtype=float32 (created by layer 'lstm_1')>, <KerasTensor: shape=(1, 12) dtype=float32 (created by layer 'lstm_1')>, <KerasTensor: shape=(1, 12) dtype=float32 (created by layer 'lstm_1')>]\n"
     ]
    }
   ],
   "source": [
    "print(timestep(np.expand_dims(train_data[0], axis=0)))\n",
    "print(lstm_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
